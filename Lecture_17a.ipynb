{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture-17a.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subhobrata/deep-learning-for-visual-computing/blob/master/Lecture_17a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "KfTrFA7pKG2X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import Function\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GaSjlWLmKYtG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "322a4e36-9c38-41ab-894a-dfdbcea92996"
      },
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "BatchSize = 1000\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./MNIST', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BatchSize,\n",
        "                                          shuffle=True, num_workers=4) # Creating dataloader\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./MNIST', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BatchSize,\n",
        "                                         shuffle=False, num_workers=4) # Creating dataloader\n",
        "\n",
        "classes = ('zero', 'one', 'two', 'three',\n",
        "           'four', 'five', 'six', 'seven', 'eight', 'nine')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mldjuaIuKczO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f17d276-6722-4231-d9c0-f4672c271925"
      },
      "cell_type": "code",
      "source": [
        "# Check availability of GPU\n",
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    print('GPU is available!')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ug7JRHibKh1W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ace047df-88dd-4fd5-bc02-5046cd86fc0e"
      },
      "cell_type": "code",
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28*28, 400),\n",
        "            nn.Tanh())\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(400, 28*28),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = autoencoder()\n",
        "print(net)\n",
        "\n",
        "if use_gpu:\n",
        "    net = net.double().cuda()\n",
        "else:\n",
        "    net = net.double()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "autoencoder(\n",
            "  (encoder): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (decoder): Sequential(\n",
            "    (0): Linear(in_features=400, out_features=784, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6Gnb-hgsK07u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "78873cb1-b250-4221-e23e-830c3dc68f08"
      },
      "cell_type": "code",
      "source": [
        "iterations = 10\n",
        "learning_rate = 0.98\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "for epoch in range(iterations):  # loop over the dataset multiple times\n",
        "    runningLoss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # wrap them in Variable\n",
        "        if use_gpu:\n",
        "            inputs = Variable(inputs.view(-1, 28*28).double()).cuda()\n",
        "        else:\n",
        "            inputs = Variable(inputs.view(-1, 28*28).double())\n",
        "\n",
        "        net.zero_grad()  # zeroes the gradient buffers of all parameters\n",
        "        outputs = net(inputs) # forward \n",
        "        loss = criterion(outputs, inputs) # calculate loss\n",
        "        loss.backward() #  backpropagate the loss\n",
        "        for f in net.parameters():\n",
        "            f.data.sub_(f.grad.data * learning_rate) # weight = weight - learning_rate * gradient (Update Weights)\n",
        "        runningLoss += loss.item()\n",
        "        \n",
        "    print('At Iteration : %d / %d  ;  Mean-Squared Error : %f'%(epoch + 1,iterations,\n",
        "                                                                        runningLoss/(60000/BatchSize)))\n",
        "print('Finished Training')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "At Iteration : 1 / 10  ;  Mean-Squared Error : 0.191208\n",
            "At Iteration : 2 / 10  ;  Mean-Squared Error : 0.100919\n",
            "At Iteration : 3 / 10  ;  Mean-Squared Error : 0.077720\n",
            "At Iteration : 4 / 10  ;  Mean-Squared Error : 0.072498\n",
            "At Iteration : 5 / 10  ;  Mean-Squared Error : 0.070350\n",
            "At Iteration : 6 / 10  ;  Mean-Squared Error : 0.069102\n",
            "At Iteration : 7 / 10  ;  Mean-Squared Error : 0.068209\n",
            "At Iteration : 8 / 10  ;  Mean-Squared Error : 0.067472\n",
            "At Iteration : 9 / 10  ;  Mean-Squared Error : 0.066801\n",
            "At Iteration : 10 / 10  ;  Mean-Squared Error : 0.066149\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "76MnPS9rLDbh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "c04e2c9e-ba4e-4fcb-b05f-71e315797adc"
      },
      "cell_type": "code",
      "source": [
        "# Adding New Layer (Stacking)\n",
        "net.encoder.add_module('New_Encoder_Layer', nn.Sequential(nn.Linear(400, 256),nn.Tanh()))\n",
        "net.encoder.add_module('New_Decoder_Layer', nn.Sequential(nn.Linear(256, 400),nn.Tanh()))\n",
        "print(net)\n",
        "if use_gpu:\n",
        "    net = net.double().cuda()\n",
        "else:\n",
        "    net = net.double()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "autoencoder(\n",
            "  (encoder): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
            "    (1): Tanh()\n",
            "    (New_Encoder_Layer): Sequential(\n",
            "      (0): Linear(in_features=400, out_features=256, bias=True)\n",
            "      (1): Tanh()\n",
            "    )\n",
            "    (New_Decoder_Layer): Sequential(\n",
            "      (0): Linear(in_features=256, out_features=400, bias=True)\n",
            "      (1): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (decoder): Sequential(\n",
            "    (0): Linear(in_features=400, out_features=784, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2orO3ul8LTUK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "594d75ba-9f96-466b-f7a3-5f60b9402ae5"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(iterations):  # loop over the dataset multiple times\n",
        "    runningLoss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # wrap them in Variable\n",
        "        if use_gpu:\n",
        "            inputs = Variable(inputs.view(-1, 28*28).double()).cuda()\n",
        "        else:\n",
        "            inputs = Variable(inputs.view(-1, 28*28).double())\n",
        "\n",
        "        net.zero_grad()  # zeroes the gradient buffers of all parameters\n",
        "        outputs = net(inputs) # forward \n",
        "        loss = criterion(outputs, inputs) # calculate loss\n",
        "        loss.backward() #  backpropagate the loss\n",
        "        for f in net.parameters():\n",
        "            f.data.sub_(f.grad.data * learning_rate) # weight = weight - learning_rate * gradient (Update Weights)\n",
        "        runningLoss += loss.item()\n",
        "        \n",
        "    print('At Iteration : %d / %d  ;  Mean-Squared Error : %f'%(epoch + 1,iterations,\n",
        "                                                                        runningLoss/(60000/BatchSize)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "At Iteration : 1 / 10  ;  Mean-Squared Error : 0.077912\n",
            "At Iteration : 2 / 10  ;  Mean-Squared Error : 0.068355\n",
            "At Iteration : 3 / 10  ;  Mean-Squared Error : 0.067962\n",
            "At Iteration : 4 / 10  ;  Mean-Squared Error : 0.067775\n",
            "At Iteration : 5 / 10  ;  Mean-Squared Error : 0.067654\n",
            "At Iteration : 6 / 10  ;  Mean-Squared Error : 0.067562\n",
            "At Iteration : 7 / 10  ;  Mean-Squared Error : 0.067487\n",
            "At Iteration : 8 / 10  ;  Mean-Squared Error : 0.067420\n",
            "At Iteration : 9 / 10  ;  Mean-Squared Error : 0.067357\n",
            "At Iteration : 10 / 10  ;  Mean-Squared Error : 0.067295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UyvLL0ZULbX3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "7744bd97-bc16-41f5-d6c3-69d45f2b168e"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Removing the decoder module from the autoencoder\n",
        "new_classifier = nn.Sequential(*list(net.children())[:-1])\n",
        "net = new_classifier\n",
        "new_classifier = nn.Sequential(*list(net[0].children())[:-1])\n",
        "net = new_classifier\n",
        "# Adding linear layer for 10-class classification problem\n",
        "net.add_module('classifier', nn.Sequential(nn.Linear(256, 10),nn.LogSoftmax()))\n",
        "print(net)\n",
        "if use_gpu:\n",
        "    net = net.double().cuda()\n",
        "else:\n",
        "    net = net.double()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=400, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Sequential(\n",
            "    (0): Linear(in_features=400, out_features=256, bias=True)\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=10, bias=True)\n",
            "    (1): LogSoftmax()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Kn1LOKVNLvzo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f3329ba8-6875-4879-c1f4-f4f1ce30401f"
      },
      "cell_type": "code",
      "source": [
        "iterations = 10\n",
        "learning_rate = 0.1\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "for epoch in range(iterations):  # loop over the dataset multiple times\n",
        "\n",
        "    runningLoss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        \n",
        "        # wrap them in Variable\n",
        "        if use_gpu:\n",
        "            inputs, labels = Variable(inputs.view(-1, 28*28).double()).cuda(), Variable(labels).cuda()\n",
        "        else:\n",
        "            inputs, labels = Variable(inputs.view(-1, 28*28).double()), Variable(labels)\n",
        "\n",
        "        net.zero_grad()  # zeroes the gradient buffers of all parameters\n",
        "        outputs = net(inputs) # forward \n",
        "        loss = criterion(outputs, labels) # calculate loss\n",
        "        loss.backward() #  backpropagate the loss\n",
        "        for f in net.parameters():\n",
        "            f.data.sub_(f.grad.data * learning_rate) # weight = weight - learning_rate * gradient (Update Weights)\n",
        "        runningLoss += loss.item()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "    for data in testloader:\n",
        "        inputs, labels = data\n",
        "        if use_gpu:\n",
        "            inputs, labels = Variable(inputs.view(-1, 28*28).double()).cuda(), labels.cuda()\n",
        "        else:\n",
        "            inputs, labels = Variable(inputs.view(-1, 28*28).double()), labels\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum()\n",
        "    print('At Iteration : %d / %d  ;  Train Error : %f ;Test Accuracy : %f'%(epoch + 1,iterations,\n",
        "                                                                        runningLoss/(60000/BatchSize),100 * correct /float(total)))\n",
        "print('Finished Training')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "At Iteration : 1 / 10  ;  Train Error : 2.026576 ;Test Accuracy : 51.000000\n",
            "At Iteration : 2 / 10  ;  Train Error : 1.069804 ;Test Accuracy : 80.000000\n",
            "At Iteration : 3 / 10  ;  Train Error : 0.643749 ;Test Accuracy : 85.000000\n",
            "At Iteration : 4 / 10  ;  Train Error : 0.484072 ;Test Accuracy : 88.000000\n",
            "At Iteration : 5 / 10  ;  Train Error : 0.410531 ;Test Accuracy : 89.000000\n",
            "At Iteration : 6 / 10  ;  Train Error : 0.371820 ;Test Accuracy : 90.000000\n",
            "At Iteration : 7 / 10  ;  Train Error : 0.344581 ;Test Accuracy : 90.000000\n",
            "At Iteration : 8 / 10  ;  Train Error : 0.326761 ;Test Accuracy : 91.000000\n",
            "At Iteration : 9 / 10  ;  Train Error : 0.312177 ;Test Accuracy : 91.000000\n",
            "At Iteration : 10 / 10  ;  Train Error : 0.299513 ;Test Accuracy : 91.000000\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sQcokrOnMCc_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "0c9d599e-d09d-4e05-d4ac-c3e23142c116"
      },
      "cell_type": "code",
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "for data in testloader:\n",
        "    images, labels = data\n",
        "    if use_gpu:\n",
        "        outputs = net(Variable(images.view(-1, 28*28).double().cuda()))\n",
        "        _, predicted = torch.max(outputs.data.cpu(), 1)\n",
        "    else:\n",
        "        outputs = net(Variable(images.view(-1, 28*28).double()))\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "    c = (predicted == labels).squeeze()\n",
        "    for i in range(BatchSize):\n",
        "        label = labels[i]\n",
        "        class_correct[label] += c[i]\n",
        "        class_total[label] += 1\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %f %%' % (\n",
        "        classes[i], 100 * class_correct[i] / float(class_total[i])))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of  zero : 0.000000 %\n",
            "Accuracy of   one : 0.000000 %\n",
            "Accuracy of   two : 6.000000 %\n",
            "Accuracy of three : 0.000000 %\n",
            "Accuracy of  four : 0.000000 %\n",
            "Accuracy of  five : 0.000000 %\n",
            "Accuracy of   six : 0.000000 %\n",
            "Accuracy of seven : 26.000000 %\n",
            "Accuracy of eight : 1.000000 %\n",
            "Accuracy of  nine : 0.000000 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "73hRoN5AMHOo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KnHsQS7bLoSX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture 19_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subhobrata/deep-learning-for-visual-computing/blob/master/Lecture_19_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "bS-UW6ksRksP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import Function\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v6zQ5AxHRr_Z",
        "colab_type": "code",
        "outputId": "32c4bb16-a86f-4f7f-a2e5-76927cf7dac9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "BatchSize = 1000\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./MNIST', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BatchSize,\n",
        "                                          shuffle=True, num_workers=4) # Creating dataloader\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./MNIST', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BatchSize,\n",
        "                                         shuffle=False, num_workers=4) # Creating dataloader\n",
        "\n",
        "classes = ('zero', 'one', 'two', 'three',\n",
        "           'four', 'five', 'six', 'seven', 'eight', 'nine')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "06HAaGqARyS4",
        "colab_type": "code",
        "outputId": "95e3561f-9acc-47fb-e8e6-7fe2bc38a02d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Check availability of GPU\n",
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    print('GPU is available!')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4hO_7JxhR2g4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class L1Penalty(torch.autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, l1weight):\n",
        "        ctx.save_for_backward(input)\n",
        "        ctx.l1weight = l1weight\n",
        "        return input\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = input.clone().sign().mul(ctx.l1weight)\n",
        "        grad_input += grad_output\n",
        "        return grad_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b2NHgk7ySDl1",
        "colab_type": "code",
        "outputId": "812cab0e-4572-423e-d5de-6f7265798820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28*28, 400),\n",
        "            nn.Tanh())\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(400, 28*28),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = L1Penalty.apply(x, 0.1)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = autoencoder()\n",
        "print(net)\n",
        "\n",
        "if use_gpu:\n",
        "    net = net.double().cuda()\n",
        "else:\n",
        "    net = net.double()\n",
        "init_weightsE = copy.deepcopy(net.encoder[0].weight.data)\n",
        "init_weightsD = copy.deepcopy(net.decoder[0].weight.data)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "autoencoder(\n",
            "  (encoder): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (decoder): Sequential(\n",
            "    (0): Linear(in_features=400, out_features=784, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PuACVrYOZAOI",
        "colab_type": "code",
        "outputId": "d6eab28d-fd42-4081-f73d-4cad7b60846e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "cell_type": "code",
      "source": [
        "iterations = 20\n",
        "learning_rate = 0.98\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "printImg = torch.Tensor(iterations/10,2,1,28,28)\n",
        "\n",
        "for epoch in range(iterations):  # loop over the dataset multiple times\n",
        "    runningLoss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # wrap them in Variable\n",
        "        if use_gpu:\n",
        "            inputs = Variable(inputs.view(-1, 28*28).double()).cuda()\n",
        "        else:\n",
        "            inputs = Variable(inputs.view(-1, 28*28).double())\n",
        "\n",
        "        net.zero_grad()  # zeroes the gradient buffers of all parameters\n",
        "        outputs = net(inputs) # forward \n",
        "        loss = criterion(outputs, inputs) # calculate loss\n",
        "        loss.backward() #  backpropagate the loss\n",
        "        for f in net.parameters():\n",
        "            f.data.sub_(f.grad.data * learning_rate) # weight = weight - learning_rate * gradient (Update Weights)\n",
        "        runningLoss += loss.data[0]\n",
        "        \n",
        "    print('At Iteration : %d / %d  ;  Mean-Squared Error : %f'%(epoch + 1,iterations,\n",
        "                                                                        runningLoss/(60000/BatchSize)))\n",
        "    if epoch%10 == 0:\n",
        "        if use_gpu:\n",
        "            outImg = net(Variable((images[0].view(-1,28*28).double().cuda()))).data\n",
        "            outImg = outImg.view(-1,28,28).cpu()\n",
        "        else:\n",
        "            outImg = net(Variable((images[0].view(-1,28*28).double()))).data\n",
        "            outImg = outImg.view(-1,28,28).cpu()\n",
        "\n",
        "        dispImg = torch.Tensor(2,1,28,28)\n",
        "        dispImg[0] = images[0]\n",
        "        dispImg[1] = outImg\n",
        "        printImg[epoch/10] = dispImg\n",
        "print('Finished Training')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-157c616ff46f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#  backpropagate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# weight = weight - learning_rate * gradient (Update Weights)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/tensor.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: function L1PenaltyBackward returned an incorrect number of gradients (expected 2, got 1)"
          ]
        }
      ]
    }
  ]
}